{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e18606",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install typing typing-extensions langgraph-graph google-generativeai dotenv pydantic json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "api_key = \"AIzaSyDh3kKmzoOOKdHbYKFKtk9DkOU5aMWBx3A\"\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    user_query: str\n",
    "    llm_result: Optional[str]\n",
    "    product_category: Optional[str]\n",
    "    query_type: Optional[str]\n",
    "\n",
    "\n",
    "def classify_message(state: State):\n",
    "    query = state[\"user_query\"]\n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "    You are an helpful AI agent. Your job is to detect if the user's query is related to\n",
    "    order status or return policy or product info or something other for user query for an Online E-Commerce store.\n",
    "    Return your response as a JSON like this: {\"query_type\": \"order_status\"}.\n",
    "    Possible query types are: order_status, return_policy, product_info, general.\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[f\"{SYSTEM_PROMPT} \\n\\nuser query: {query}\"]\n",
    ")\n",
    "    response = json.loads(query_type)\n",
    "    state[\"query_type\"] = response.get(\"query_type\")\n",
    "    return state\n",
    "\n",
    "def classify_product(state: State):\n",
    "    query = state[\"user_query\"]\n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "    You are an helpful AI agent. Your job is to classify the product referred in user's query out of\n",
    "    the following categories:\n",
    "    Electronics and Computer hardware, Food , Clothes and Wear, Bags, Cookwares and utensils,\n",
    "    Books, Notebooks and Stationery, Toys, Sports equipments or others\n",
    "    Return your response only in JSON format like this: {\"product_category\": \"Electronics and Computer hardware\"}.\n",
    "\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[f\"{SYSTEM_PROMPT} \\n\\nuser query: {query}\"]\n",
    ")\n",
    "    response = json.loads(response_text)\n",
    "    state[\"product_category\"] = response.get(\"product_category\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def returnpolicy(state: State):\n",
    "    query = state[\"user_query\"]\n",
    "    SYSTEM_PROMPT = \"\"\"Based on the product_category generated from user's query\n",
    "    generate a return policy for the product.\n",
    "    Return your response in format:\n",
    "    Return Policy:\n",
    "    Points describing the return policy for the product category.\n",
    "    \"\"\"\n",
    "    if state[\"query_type\"] != \"return_policy\":\n",
    "        return state\n",
    "    if state[\"product_category\"] is None:\n",
    "        return state\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[f\"{SYSTEM_PROMPT} \\n\\nuser query: {query} \\n\\nproduct_category: {state['product_category']}\"]\n",
    ")\n",
    "    state[\"llm_result\"] = response.text\n",
    "    return state\n",
    "\n",
    "def product_info(state: State):\n",
    "    query = state[\"user_query\"]\n",
    "    SYSTEM_PROMPT = \"\"\"Based on the product_category generated from user's query\n",
    "    generate a product info for the product.\n",
    "    Return your response in format:\n",
    "    Product Info:\n",
    "    Points describing the product info for the product category.\n",
    "    \"\"\"\n",
    "    if state[\"query_type\"] != \"product_info\":\n",
    "        return state\n",
    "    if state[\"product_category\"] is None:\n",
    "        return state\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[f\"{SYSTEM_PROMPT} \\n\\nuser query: {query} \\n\\nproduct_category: {state['product_category']}\"]\n",
    ")\n",
    "    state[\"llm_result\"] = response.text\n",
    "    return state\n",
    "\n",
    "def app_tracker(state: State):\n",
    "    query = state[\"user_query\"]\n",
    "    SYSTEM_PROMPT = \"\"\"You are an helpful AI agent. Your job is to track the order status of the user's query.\n",
    "    Return your response in format:\n",
    "    Order Status:\n",
    "    Points describing the order status for the user's query.\n",
    "\n",
    "    \"\"\"\n",
    "    if state[\"query_type\"] != \"order_status\":\n",
    "        return state\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[f\"{SYSTEM_PROMPT} \\n\\nuser query: {query}\"]\n",
    ")\n",
    "    state[\"llm_result\"] = response.text\n",
    "    return state\n",
    "def general_query(state: State):\n",
    "    query = state[\"user_query\"]\n",
    "    if state[\"query_type\"] != \"other\":\n",
    "        return state\n",
    "    SYSTEM_PROMPT = \"\"\"You are an helpful AI agent. Your job is to answer the users query in a general way.\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[f\"{SYSTEM_PROMPT} \\n\\nuser query: {query}\"]\n",
    ")\n",
    "    state[\"llm_result\"] = response.text\n",
    "    return state\n",
    "def route_query(state: State) -> Literal[\"order_status\", \"return_policy\", \"product_info\", \"others\"]:\n",
    "    return f\"{state['query_type']}_query\"\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"classify_product\", classify_product)\n",
    "graph_builder.add_node(\"classify_message\", classify_message)\n",
    "graph_builder.add_node(\"order_status\", app_tracker)\n",
    "graph_builder.add_node(\"return_policy\", returnpolicy)\n",
    "graph_builder.add_node(\"product_info\", product_info)\n",
    "graph_builder.add_node(\"others\", general_query)\n",
    "\n",
    "graph_builder.add_edge(START, \"classify_product\")\n",
    "graph_builder.add_edges(\"classify_product\", \"classify_message\")\n",
    "graph_builder.add_conditional_edges(\"classifymessage\", route_query)\n",
    "graph_builder.add_edge(\"order_state\", END)\n",
    "graph_builder.add_edge(\"return_policy\", END)\n",
    "graph_builder.add_edge(\"product_info\", END)\n",
    "graph_builder.add_edge(\"others\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "\n",
    "def main():\n",
    "    user = input(\"> \")\n",
    "    _state: State = {\n",
    "        'user_query': user,\n",
    "        'llm_result': None,\n",
    "        'product_category': None,\n",
    "        'query_type': None  # type: Literal[\"order_status\", \"return_policy\",\n",
    "    }\n",
    "    graph_result = graph.invoke(_state)\n",
    "    print(\n",
    "        \"\\nðŸ§  Response from graph:\\n\",\n",
    "        graph_result.get(\"llm_result\", \"accuracy\", \"quantify\", \"query_type\"),\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
